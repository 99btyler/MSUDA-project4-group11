{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Global sales\" model (optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tyler/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Year of Release</th>\n",
       "      <th>Critic Score</th>\n",
       "      <th>User Score</th>\n",
       "      <th>NA Sales</th>\n",
       "      <th>EU Sales</th>\n",
       "      <th>JP Sales</th>\n",
       "      <th>Other Sales</th>\n",
       "      <th>Global Sales</th>\n",
       "      <th>Platform_3DS</th>\n",
       "      <th>...</th>\n",
       "      <th>Genre_Sports</th>\n",
       "      <th>Genre_Strategy</th>\n",
       "      <th>Rating_AO</th>\n",
       "      <th>Rating_E</th>\n",
       "      <th>Rating_E10+</th>\n",
       "      <th>Rating_K-A</th>\n",
       "      <th>Rating_M</th>\n",
       "      <th>Rating_RP</th>\n",
       "      <th>Rating_T</th>\n",
       "      <th>Rating_Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167</td>\n",
       "      <td>2006</td>\n",
       "      <td>76.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>41.36</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>82.53</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>167</td>\n",
       "      <td>2008</td>\n",
       "      <td>82.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>15.68</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>35.52</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>167</td>\n",
       "      <td>2009</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>32.77</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>167</td>\n",
       "      <td>2006</td>\n",
       "      <td>89.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>11.28</td>\n",
       "      <td>9.14</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2.88</td>\n",
       "      <td>29.80</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>167</td>\n",
       "      <td>2006</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>13.96</td>\n",
       "      <td>9.18</td>\n",
       "      <td>2.93</td>\n",
       "      <td>2.84</td>\n",
       "      <td>28.92</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Publisher  Year of Release  Critic Score  User Score  NA Sales  EU Sales  \\\n",
       "0        167             2006          76.0         8.0     41.36     28.96   \n",
       "1        167             2008          82.0         8.3     15.68     12.76   \n",
       "2        167             2009          80.0         8.0     15.61     10.93   \n",
       "3        167             2006          89.0         8.5     11.28      9.14   \n",
       "4        167             2006          58.0         6.6     13.96      9.18   \n",
       "\n",
       "   JP Sales  Other Sales  Global Sales  Platform_3DS  ...  Genre_Sports  \\\n",
       "0      3.77         8.45         82.53         False  ...          True   \n",
       "1      3.79         3.29         35.52         False  ...         False   \n",
       "2      3.28         2.95         32.77         False  ...          True   \n",
       "3      6.50         2.88         29.80         False  ...         False   \n",
       "4      2.93         2.84         28.92         False  ...         False   \n",
       "\n",
       "   Genre_Strategy  Rating_AO  Rating_E  Rating_E10+  Rating_K-A  Rating_M  \\\n",
       "0           False      False      True        False       False     False   \n",
       "1           False      False      True        False       False     False   \n",
       "2           False      False      True        False       False     False   \n",
       "3           False      False      True        False       False     False   \n",
       "4           False      False      True        False       False     False   \n",
       "\n",
       "   Rating_RP  Rating_T  Rating_Unknown  \n",
       "0      False     False           False  \n",
       "1      False     False           False  \n",
       "2      False     False           False  \n",
       "3      False     False           False  \n",
       "4      False     False           False  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df = pd.read_csv(\"output/model_data.csv\")\n",
    "\n",
    "model_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling (optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the target (y) and features (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model_df[\"Global Sales\"] # target\n",
    "X = model_df.drop(columns=[\"Global Sales\"]) # features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data: 80% training and 20% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training, X_testing, y_training, y_testing = train_test_split(X, y, test_size=.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() # mean=0, standard_deviation=1\n",
    "\n",
    "X_training = scaler.fit_transform(X_training)\n",
    "X_testing = scaler.fit_transform(X_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the regression model (optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tyler/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        # layer 1\n",
    "        keras.layers.Dense(128, activation=\"relu\", input_shape=(X_training.shape[1],)),\n",
    "        # layer 2\n",
    "        keras.layers.Dense(64, activation=\"relu\"),\n",
    "        # layer 3\n",
    "        keras.layers.Dense(32, activation=\"relu\"),\n",
    "        # layer 4\n",
    "        keras.layers.Dense(16, activation=\"relu\"),\n",
    "        # output layer\n",
    "        keras.layers.Dense(1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=[keras.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluating the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2.7231 - root_mean_squared_error: 1.6104 - val_loss: 0.1496 - val_root_mean_squared_error: 0.3868\n",
      "Epoch 2/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 0.0630 - root_mean_squared_error: 0.2501 - val_loss: 0.1117 - val_root_mean_squared_error: 0.3342\n",
      "Epoch 3/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - loss: 0.0344 - root_mean_squared_error: 0.1844 - val_loss: 0.0946 - val_root_mean_squared_error: 0.3075\n",
      "Epoch 4/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - loss: 0.0149 - root_mean_squared_error: 0.1219 - val_loss: 0.1116 - val_root_mean_squared_error: 0.3340\n",
      "Epoch 5/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 0.0097 - root_mean_squared_error: 0.0981 - val_loss: 0.1010 - val_root_mean_squared_error: 0.3179\n",
      "Epoch 6/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - loss: 0.0128 - root_mean_squared_error: 0.1131 - val_loss: 0.1169 - val_root_mean_squared_error: 0.3419\n",
      "Epoch 7/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - loss: 0.0057 - root_mean_squared_error: 0.0755 - val_loss: 0.1097 - val_root_mean_squared_error: 0.3312\n",
      "Epoch 8/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - loss: 0.0060 - root_mean_squared_error: 0.0769 - val_loss: 0.1126 - val_root_mean_squared_error: 0.3355\n",
      "Epoch 9/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - loss: 0.0050 - root_mean_squared_error: 0.0706 - val_loss: 0.1253 - val_root_mean_squared_error: 0.3540\n",
      "Epoch 10/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - loss: 0.0468 - root_mean_squared_error: 0.2093 - val_loss: 0.0786 - val_root_mean_squared_error: 0.2803\n",
      "Epoch 11/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 0.0158 - root_mean_squared_error: 0.1194 - val_loss: 0.0947 - val_root_mean_squared_error: 0.3078\n",
      "Epoch 12/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - loss: 0.0121 - root_mean_squared_error: 0.1093 - val_loss: 0.0839 - val_root_mean_squared_error: 0.2896\n",
      "Epoch 13/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - loss: 0.0128 - root_mean_squared_error: 0.1119 - val_loss: 0.0992 - val_root_mean_squared_error: 0.3150\n",
      "Epoch 14/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - loss: 0.0088 - root_mean_squared_error: 0.0920 - val_loss: 0.1123 - val_root_mean_squared_error: 0.3351\n",
      "Epoch 15/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 0.0056 - root_mean_squared_error: 0.0740 - val_loss: 0.1172 - val_root_mean_squared_error: 0.3424\n",
      "Epoch 16/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - loss: 0.0039 - root_mean_squared_error: 0.0623 - val_loss: 0.0776 - val_root_mean_squared_error: 0.2786\n",
      "Epoch 17/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 0.0064 - root_mean_squared_error: 0.0788 - val_loss: 0.0646 - val_root_mean_squared_error: 0.2542\n",
      "Epoch 18/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 0.0654 - root_mean_squared_error: 0.2431 - val_loss: 0.1146 - val_root_mean_squared_error: 0.3385\n",
      "Epoch 19/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - loss: 0.1669 - root_mean_squared_error: 0.3863 - val_loss: 0.1105 - val_root_mean_squared_error: 0.3324\n",
      "Epoch 20/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - loss: 0.0435 - root_mean_squared_error: 0.1980 - val_loss: 0.1153 - val_root_mean_squared_error: 0.3395\n",
      "Epoch 21/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 0.0082 - root_mean_squared_error: 0.0895 - val_loss: 0.0839 - val_root_mean_squared_error: 0.2897\n",
      "Epoch 22/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - loss: 0.3076 - root_mean_squared_error: 0.5174 - val_loss: 0.0781 - val_root_mean_squared_error: 0.2795\n",
      "Epoch 23/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 0.0180 - root_mean_squared_error: 0.1309 - val_loss: 0.1282 - val_root_mean_squared_error: 0.3581\n",
      "Epoch 24/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 0.0071 - root_mean_squared_error: 0.0845 - val_loss: 0.0412 - val_root_mean_squared_error: 0.2030\n",
      "Epoch 25/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - loss: 0.0348 - root_mean_squared_error: 0.1830 - val_loss: 0.0864 - val_root_mean_squared_error: 0.2939\n",
      "Epoch 26/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - loss: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0997 - val_root_mean_squared_error: 0.3158\n",
      "Epoch 27/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 0.0026 - root_mean_squared_error: 0.0512 - val_loss: 0.0968 - val_root_mean_squared_error: 0.3111\n",
      "Epoch 28/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - loss: 0.0020 - root_mean_squared_error: 0.0442 - val_loss: 0.1022 - val_root_mean_squared_error: 0.3197\n",
      "Epoch 29/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 0.0020 - root_mean_squared_error: 0.0442 - val_loss: 0.0758 - val_root_mean_squared_error: 0.2753\n",
      "Epoch 30/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - loss: 0.0020 - root_mean_squared_error: 0.0448 - val_loss: 0.1230 - val_root_mean_squared_error: 0.3507\n",
      "Epoch 31/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - loss: 0.0018 - root_mean_squared_error: 0.0420 - val_loss: 0.0959 - val_root_mean_squared_error: 0.3096\n",
      "Epoch 32/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 0.0035 - root_mean_squared_error: 0.0573 - val_loss: 0.0950 - val_root_mean_squared_error: 0.3083\n",
      "Epoch 33/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - loss: 0.0852 - root_mean_squared_error: 0.2840 - val_loss: 0.0824 - val_root_mean_squared_error: 0.2871\n",
      "Epoch 34/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 0.0176 - root_mean_squared_error: 0.1299 - val_loss: 0.0953 - val_root_mean_squared_error: 0.3088\n",
      "Epoch 35/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - loss: 0.0058 - root_mean_squared_error: 0.0748 - val_loss: 0.0982 - val_root_mean_squared_error: 0.3134\n",
      "Epoch 36/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 0.0081 - root_mean_squared_error: 0.0895 - val_loss: 0.0969 - val_root_mean_squared_error: 0.3113\n",
      "Epoch 37/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 0.0030 - root_mean_squared_error: 0.0547 - val_loss: 0.1222 - val_root_mean_squared_error: 0.3496\n",
      "Epoch 38/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 0.0165 - root_mean_squared_error: 0.1226 - val_loss: 0.0692 - val_root_mean_squared_error: 0.2631\n",
      "Epoch 39/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 0.2056 - root_mean_squared_error: 0.4304 - val_loss: 0.1360 - val_root_mean_squared_error: 0.3688\n",
      "Epoch 40/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 0.0914 - root_mean_squared_error: 0.2907 - val_loss: 0.0683 - val_root_mean_squared_error: 0.2614\n",
      "Epoch 41/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0325 - root_mean_squared_error: 0.1590 - val_loss: 0.1159 - val_root_mean_squared_error: 0.3405\n",
      "Epoch 42/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - loss: 0.1256 - root_mean_squared_error: 0.3388 - val_loss: 0.0725 - val_root_mean_squared_error: 0.2693\n",
      "Epoch 43/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - loss: 0.0109 - root_mean_squared_error: 0.1021 - val_loss: 0.0985 - val_root_mean_squared_error: 0.3139\n",
      "Epoch 44/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 0.0128 - root_mean_squared_error: 0.1117 - val_loss: 0.0908 - val_root_mean_squared_error: 0.3013\n",
      "Epoch 45/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - loss: 0.0029 - root_mean_squared_error: 0.0527 - val_loss: 0.1474 - val_root_mean_squared_error: 0.3839\n",
      "Epoch 46/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - loss: 0.0069 - root_mean_squared_error: 0.0795 - val_loss: 0.1147 - val_root_mean_squared_error: 0.3387\n",
      "Epoch 47/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - loss: 0.0075 - root_mean_squared_error: 0.0837 - val_loss: 0.1035 - val_root_mean_squared_error: 0.3217\n",
      "Epoch 48/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - loss: 0.0013 - root_mean_squared_error: 0.0365 - val_loss: 0.0771 - val_root_mean_squared_error: 0.2777\n",
      "Epoch 49/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 0.0015 - root_mean_squared_error: 0.0387 - val_loss: 0.1164 - val_root_mean_squared_error: 0.3411\n",
      "Epoch 50/50\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - loss: 0.0018 - root_mean_squared_error: 0.0427 - val_loss: 0.0775 - val_root_mean_squared_error: 0.2783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x173215790>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_training, y_training, epochs=50, batch_size=32, validation_data=(X_testing, y_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 0.0604 - root_mean_squared_error: 0.2438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0774657279253006, 0.2783266603946686]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_testing, y_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step\n",
      "r2: 0.971492258499782\n"
     ]
    }
   ],
   "source": [
    "y_prediction = model.predict(X_testing)\n",
    "\n",
    "r2 = r2_score(y_testing, y_prediction)\n",
    "print(f\"r2: {r2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
